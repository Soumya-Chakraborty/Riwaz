# ML Model Training Pipeline for Riwaz

This directory contains the training pipeline, scripts, and documentation for all machine learning models used in the Riwaz application.

## ğŸ“ Directory Structure

```
ml_training/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ pitch_detection/                   # Pitch detection model training
â”‚   â”œâ”€â”€ train_pitch_model.py
â”‚   â”œâ”€â”€ data_preparation.py
â”‚   â”œâ”€â”€ model_architecture.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ swar_classification/               # Swar classification model training
â”‚   â”œâ”€â”€ train_swar_classifier.py
â”‚   â”œâ”€â”€ data_preparation.py
â”‚   â”œâ”€â”€ model_architecture.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ raga_classification/               # GMM raga classifier
â”‚   â”œâ”€â”€ train_gmm_classifier.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ data/                              # Training data (not in git)
â”‚   â”œâ”€â”€ pitch_dataset/
â”‚   â”œâ”€â”€ swar_dataset/
â”‚   â””â”€â”€ raga_dataset/
â”œâ”€â”€ models/                            # Trained models (not in git)
â”‚   â”œâ”€â”€ pitch_model.h5
â”‚   â”œâ”€â”€ pitch_model.tflite
â”‚   â”œâ”€â”€ swar_classifier.h5
â”‚   â””â”€â”€ swar_classifier.tflite
â””â”€â”€ utils/                             # Shared utilities
    â”œâ”€â”€ audio_processing.py
    â”œâ”€â”€ tflite_converter.py
    â””â”€â”€ evaluation.py
```

## ğŸ¯ Models Overview

### 1. Pitch Detection Model (Neural Network)
- **Architecture**: CREPE-inspired CNN
- **Input**: Raw audio waveform (1024 samples)
- **Output**: Pitch frequency + confidence
- **Framework**: TensorFlow/Keras
- **Target Size**: < 5 MB

### 2. Swar Classification Model (CNN)
- **Architecture**: Mel-spectrogram CNN
- **Input**: Mel spectrogram (128x128)
- **Output**: 12 swar classes + confidence
- **Framework**: TensorFlow/Keras
- **Target Size**: < 10 MB

### 3. Raga Classification Model (GMM)
- **Architecture**: Gaussian Mixture Models
- **Input**: Pitch sequence features
- **Output**: Raga probabilities (10 ragas)
- **Framework**: Scikit-learn
- **Implementation**: Pure Kotlin (no TFLite needed)

## ğŸš€ Quick Start

### Prerequisites
```bash
# Python 3.8+
pip install tensorflow==2.14.0
pip install librosa
pip install scikit-learn
pip install numpy
pip install matplotlib
```

### Training Workflow

1. **Collect/Prepare Data**
   ```bash
   python pitch_detection/data_preparation.py --input raw_audio/ --output data/pitch_dataset/
   ```

2. **Train Model**
   ```bash
   python pitch_detection/train_pitch_model.py --epochs 100 --batch-size 32
   ```

3. **Convert to TFLite**
   ```bash
   python utils/tflite_converter.py --model models/pitch_model.h5 --output models/pitch_model.tflite
   ```

4. **Deploy to Android**
   ```bash
   cp models/pitch_model.tflite ../app/src/main/assets/
   ```

## ğŸ“Š Data Collection Guidelines

### For Pitch Detection
- **Required**: 10,000+ labeled audio samples
- **Duration**: 1-2 seconds per sample
- **Format**: WAV, 44.1kHz, mono
- **Labels**: Ground truth pitch (Hz)
- **Sources**: 
  - Synthesized pure tones
  - Real vocal recordings with reference pitch
  - Indian classical music recordings

### For Swar Classification
- **Required**: 5,000+ samples per swar class (60,000 total)
- **Duration**: 0.5-1 second per sample
- **Format**: WAV, 44.1kHz, mono
- **Labels**: Swar name (Sa, Re, Ga, etc.)
- **Sources**:
  - Recordings from trained musicians
  - Synthesized swar samples
  - Extracted from raga performances

### For Raga Classification
- **Required**: 100+ recordings per raga (1,000 total)
- **Duration**: 30-60 seconds per recording
- **Format**: WAV, 44.1kHz, mono
- **Labels**: Raga name
- **Sources**:
  - Professional raga performances
  - Student practice sessions
  - Curated classical music database

## ğŸ”§ Model Architecture Details

### Pitch Detection (CREPE-style)
```python
Input: [batch, 1024, 1]
  â†“
Conv1D(1024, kernel=512, stride=4) + ReLU
  â†“
Conv1D(128, kernel=64, stride=1) + ReLU
  â†“
Conv1D(128, kernel=64, stride=1) + ReLU
  â†“
MaxPool1D(pool=2)
  â†“
Flatten
  â†“
Dense(256) + ReLU + Dropout(0.25)
  â†“
Dense(360)  # Pitch bins (50-500 Hz)
  â†“
Softmax
Output: [batch, 360] (pitch probability distribution)
```

### Swar Classification (Mel-CNN)
```python
Input: [batch, 128, 128, 1]  # Mel spectrogram
  â†“
Conv2D(32, 3x3) + ReLU + BatchNorm
  â†“
MaxPool2D(2x2)
  â†“
Conv2D(64, 3x3) + ReLU + BatchNorm
  â†“
MaxPool2D(2x2)
  â†“
Conv2D(128, 3x3) + ReLU + BatchNorm
  â†“
GlobalAveragePooling2D
  â†“
Dense(128) + ReLU + Dropout(0.5)
  â†“
Dense(12)  # 12 swar classes
  â†“
Softmax
Output: [batch, 12] (swar probabilities)
```

## ğŸ“ˆ Training Best Practices

### Data Augmentation
- Pitch shifting (Â±2 semitones)
- Time stretching (0.9x - 1.1x)
- Background noise addition
- Volume variation

### Hyperparameters
- **Learning Rate**: 0.001 (Adam optimizer)
- **Batch Size**: 32-64
- **Epochs**: 50-100
- **Early Stopping**: Patience = 10

### Validation Strategy
- 80/10/10 train/val/test split
- Stratified sampling by class
- Cross-validation for small datasets

## ğŸ¯ Performance Targets

| Model | Metric | Target | Current |
|-------|--------|--------|---------|
| Pitch Detection | Accuracy (Â±50 cents) | > 95% | TBD |
| Pitch Detection | Inference Time | < 50ms | TBD |
| Swar Classification | Top-1 Accuracy | > 90% | TBD |
| Swar Classification | Top-3 Accuracy | > 98% | TBD |
| Raga Classification | Top-1 Accuracy | > 80% | TBD |
| Raga Classification | Top-3 Accuracy | > 95% | TBD |

## ğŸ”„ Model Update Workflow

1. **Collect new data** â†’ Add to `data/` directory
2. **Retrain model** â†’ Run training script
3. **Evaluate performance** â†’ Compare with baseline
4. **Convert to TFLite** â†’ Optimize for mobile
5. **Test on device** â†’ Verify inference speed
6. **Deploy** â†’ Copy to `app/src/main/assets/`
7. **Version control** â†’ Tag release in git

## ğŸ“ Model Versioning

Models should be versioned using semantic versioning:
- `pitch_model_v1.0.0.tflite`
- `swar_classifier_v1.0.0.tflite`

Version increments:
- **Major**: Architecture changes
- **Minor**: Significant accuracy improvements
- **Patch**: Bug fixes, minor improvements

## ğŸ§ª Testing & Evaluation

### Unit Tests
```bash
python -m pytest tests/
```

### Model Evaluation
```bash
python utils/evaluation.py --model models/pitch_model.tflite --test-data data/pitch_dataset/test/
```

### Android Integration Test
1. Deploy model to device
2. Run app with test recordings
3. Compare ML vs DSP results
4. Measure inference latency

## ğŸ“š References

- **CREPE**: Kim et al., "CREPE: A Convolutional Representation for Pitch Estimation" (2018)
- **Mel Spectrograms**: Logan, "Mel Frequency Cepstral Coefficients for Music Modeling" (2000)
- **GMM for Music**: Pampalk et al., "Content-based organization and visualization of music archives" (2002)
- **TensorFlow Lite**: https://www.tensorflow.org/lite
- **Indian Classical Music Theory**: Bhatkhande Notation System

## ğŸ¤ Contributing

When adding new models or improving existing ones:
1. Document architecture changes
2. Provide training scripts
3. Include evaluation metrics
4. Update this README
5. Create pull request with model performance comparison

## ğŸ“§ Contact

For questions about the ML pipeline, contact the ML team or create an issue in the repository.
